{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3cc416b",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "355eb2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before dropna:  (699, 11)\n",
      "Shape after dropna:  (683, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>clump_thickness</th>\n",
       "      <th>size_uniformity</th>\n",
       "      <th>shape_uniformity</th>\n",
       "      <th>marginal_adhesion</th>\n",
       "      <th>epithelial_size</th>\n",
       "      <th>bare_nucleoli</th>\n",
       "      <th>bland_chromatin</th>\n",
       "      <th>normal_nucleoli</th>\n",
       "      <th>mitoses</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  clump_thickness  size_uniformity  shape_uniformity  \\\n",
       "0  1000025                5                1                 1   \n",
       "1  1002945                5                4                 4   \n",
       "2  1015425                3                1                 1   \n",
       "3  1016277                6                8                 8   \n",
       "4  1017023                4                1                 1   \n",
       "\n",
       "   marginal_adhesion  epithelial_size bare_nucleoli  bland_chromatin  \\\n",
       "0                  1                2             1                3   \n",
       "1                  5                7            10                3   \n",
       "2                  1                2             2                3   \n",
       "3                  1                3             4                3   \n",
       "4                  3                2             1                3   \n",
       "\n",
       "   normal_nucleoli  mitoses  target  \n",
       "0                1        1       2  \n",
       "1                2        1       2  \n",
       "2                1        1       2  \n",
       "3                7        1       2  \n",
       "4                1        1       2  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#set column names\n",
    "column_name = ['id', 'clump_thickness', 'size_uniformity', 'shape_uniformity', \n",
    "            'marginal_adhesion', 'epithelial_size', 'bare_nucleoli', 'bland_chromatin'\n",
    "             , 'normal_nucleoli', 'mitoses', 'target']\n",
    "\n",
    "df=pd.read_csv('C:/Users/windows10/Desktop/breast-cancer-wisconsin.csv',names=column_name)\n",
    "print('Shape before dropna: ',df.shape)\n",
    "#df.replace({\"?\":np.nan},inplace=True)\n",
    "#df.dropna(axis=0,inplace=True)\n",
    "for c in column_name:\n",
    "  df=df[pd.to_numeric(df[c],errors='coerce').notnull()]\n",
    "print('Shape after dropna: ',df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04281083",
   "metadata": {},
   "source": [
    "Dataset Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7c4956c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sscaler(data):\n",
    "    scaler_train =  data.drop(['target','id'], axis=1)\n",
    "    std = StandardScaler()\n",
    "    Stand_scale = std.fit_transform(scaler_train)\n",
    "    \n",
    "    Stand_scale = pd.DataFrame(Stand_scale, columns = scaler_train.columns)\n",
    "\n",
    "    return Stand_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac1fc2e",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bff68e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def D_tree(X_train, X_test, y_train, y_test, kf, mode):\n",
    "    \n",
    "    criterion='gini'\n",
    "    if mode==0:\n",
    "      #Using Gini \n",
    "      gini = DecisionTreeClassifier(criterion = criterion, random_state = 1, max_depth =2, min_samples_leaf = 5)\n",
    "      gini.fit(X_train, y_train)\n",
    "    \n",
    "      y_pred = gini.predict(X_test)\n",
    "    \n",
    "      gini_accuracy = accuracy_score(y_pred, y_test)\n",
    "      gini_training = accuracy_score(gini.predict(X_train), y_train)\n",
    "    \n",
    "      print('test_accuracy(gini):', accuracy_score(y_pred, y_test))\n",
    "      print('training_accuracy(gini):', accuracy_score(gini.predict(X_train), y_train))\n",
    "      print()\n",
    "    \n",
    "    else:\n",
    "      #Using Entropy\n",
    "      criterion='entropy'\n",
    "      entropy = DecisionTreeClassifier(criterion = criterion, random_state = 1, max_depth=5, min_samples_leaf = 5)\n",
    "      entropy.fit(X_train, y_train)\n",
    "\n",
    "      y_pred = entropy.predict(X_test)\n",
    "    \n",
    "      entropy_accuracy = accuracy_score(y_pred, y_test)\n",
    "      entropy_training = accuracy_score(entropy.predict(X_train), y_train)\n",
    "    \n",
    "      print('test_accuracy(entropy):', accuracy_score(y_pred, y_test))\n",
    "      print('training_accuracy(entropy):', accuracy_score(entropy.predict(X_train), y_train))\n",
    "      print()\n",
    "     \n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    \n",
    "    param_grid = {\n",
    "            \"max_depth\": [2, 3, 4, 5, 6, 7, 10],\n",
    "            'max_features': [None, 'sqrt', 'log2', 3],\n",
    "            'min_samples_leaf': [1, 2, 3],\n",
    "            \"min_samples_split\": [2, 3, 4, 5, 6, 10]\n",
    "            }\n",
    "    \n",
    "    grid_dtree = GridSearchCV(DecisionTreeClassifier(criterion=criterion,random_state=42),\n",
    "                              param_grid=param_grid,cv=kf)\n",
    "    \n",
    "    grid_dtree.fit(X_train, y_train)\n",
    "    \n",
    "    best_params = grid_dtree.best_params_\n",
    "    best_score = round(grid_dtree.best_score_, 4)\n",
    "    return best_params, best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50aa1493",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb79d730",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def svm(X_train, X_test, y_train, y_test, kf):\n",
    "    \n",
    "    #svm hyperparameter\n",
    "    #C: penalty for misclassified data\n",
    "    #gamma: controls the distance of influence of a single training point\n",
    "    #kernel: default='rbf'\n",
    "      \n",
    "    param_grid = {\n",
    "            \"C\": [10,1,0.1,0.01],\n",
    "            'gamma':[10,1,0.1,0.01,0.001],\n",
    "            'kernel': ['linear','poly','rbf','sigmoid']\n",
    "            }\n",
    "    grid_svm = GridSearchCV(SVC(random_state=42),\n",
    "                              param_grid=param_grid,cv=kf)\n",
    "    \n",
    "    grid_svm.fit(X_train, y_train)\n",
    "    \n",
    "    best_params = grid_svm.best_params_               \n",
    "    best_score = round(grid_svm.best_score_, 4) \n",
    "    \n",
    "    return best_params, best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679b9806",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f7a5aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogisticRegressor(X_train, X_test, y_train, y_test,kf):\n",
    "    #reg = LogisticRegression(solver = 'lbfgs', max_iter=1000)\n",
    "    #reg.fit(X_train, y_train)\n",
    "    #train_score = reg.score(X_train, y_train)\n",
    "    #test_score = reg.score(X_test, y_test)\n",
    "    #cv_scores = cross_val_score(reg, X_test, y_test, cv=5)\n",
    "    param_grid={\n",
    "        #\"penalty\":['l1','l2','elasticnet','none'],\n",
    "        \"C\":[10,1,0.1,0.01,0.001],\n",
    "        \"solver\": ['newton-cg','lbfgs','liblinear','sag','saga'],\n",
    "        \"max_iter\":[1000,1500,2000]\n",
    "        }\n",
    "    grid_logistic=GridSearchCV(LogisticRegression(),\n",
    "                            param_grid=param_grid,cv=kf)\n",
    "    grid_logistic.fit(X_train, y_train)\n",
    "    best_params=grid_logistic.best_params_\n",
    "    best_score=round(grid_logistic.best_score_,4)\n",
    "    return best_params, best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b85c8f5",
   "metadata": {},
   "source": [
    "Run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7280478a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def run_model(df, n_split, model,scale):\n",
    "    #if scale parameter is 1, scale the dataset\n",
    "    if scale==1:\n",
    "        X=sscaler(df)\n",
    "    else:\n",
    "        X=df.drop(columns=['target','id'])\n",
    "    y=df['target']\n",
    "\n",
    "    kf=KFold(n_splits=n_split,shuffle=True,random_state=10)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,train_size=0.7)\n",
    "    \n",
    "    # Decision Tree with Gini\n",
    "    if model==1:\n",
    "        best_param, best_score=D_tree(X_train, X_test, y_train, y_test,kf,0)\n",
    "    \n",
    "    # Decision Tree with Entrophy\n",
    "    elif model==2:\n",
    "        best_param, best_score=D_tree(X_train, X_test, y_train, y_test,kf,1)\n",
    "    \n",
    "    #SVM\n",
    "    elif model==3:\n",
    "        best_param, best_score=svm(X_train, X_test, y_train, y_test,kf)\n",
    "  \n",
    "    #Logistic Regression\n",
    "    else:\n",
    "        best_param, best_score=LogisticRegressor(X_train, X_test, y_train, y_test,kf)\n",
    "    print('best param: {}\\nbest score: {}\\n'.format(best_param, best_score))\n",
    "    return best_param, best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d53cdaa",
   "metadata": {},
   "source": [
    "Giant function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdde48ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Decision Tree with Gini\n",
      "\n",
      "k value: 3\n",
      "test_accuracy(gini): 0.9414634146341463\n",
      "training_accuracy(gini): 0.9665271966527197\n",
      "\n",
      "best param: {'max_depth': 4, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 10}\n",
      "best score: 0.9708\n",
      "\n",
      "k value: 5\n",
      "test_accuracy(gini): 0.9414634146341463\n",
      "training_accuracy(gini): 0.9560669456066946\n",
      "\n",
      "best param: {'max_depth': 4, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 10}\n",
      "best score: 0.9602\n",
      "\n",
      "k value: 7\n",
      "test_accuracy(gini): 0.9317073170731708\n",
      "training_accuracy(gini): 0.9497907949790795\n",
      "\n",
      "best param: {'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "best score: 0.9518\n",
      "\n",
      "Model: Decision Tree with Entropy\n",
      "\n",
      "k value: 3\n",
      "test_accuracy(entropy): 0.9560975609756097\n",
      "training_accuracy(entropy): 0.9728033472803347\n",
      "\n",
      "best param: {'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "best score: 0.9373\n",
      "\n",
      "k value: 5\n",
      "test_accuracy(entropy): 0.9512195121951219\n",
      "training_accuracy(entropy): 0.9686192468619247\n",
      "\n",
      "best param: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 2}\n",
      "best score: 0.9561\n",
      "\n",
      "k value: 7\n",
      "test_accuracy(entropy): 0.9512195121951219\n",
      "training_accuracy(entropy): 0.9748953974895398\n",
      "\n",
      "best param: {'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 4}\n",
      "best score: 0.9644\n",
      "\n",
      "Model: SVM\n",
      "\n",
      "k value: 3\n",
      "best param: {'C': 0.1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "best score: 0.977\n",
      "\n",
      "k value: 5\n",
      "best param: {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "best score: 0.9728\n",
      "\n",
      "k value: 7\n",
      "best param: {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "best score: 0.9602\n",
      "\n",
      "Model: Logistic Regression\n",
      "\n",
      "k value: 3\n",
      "best param: {'C': 0.1, 'max_iter': 1000, 'solver': 'saga'}\n",
      "best score: 0.9707\n",
      "\n",
      "k value: 5\n",
      "best param: {'C': 0.1, 'max_iter': 1000, 'solver': 'sag'}\n",
      "best score: 0.9623\n",
      "\n",
      "k value: 7\n",
      "best param: {'C': 0.1, 'max_iter': 1000, 'solver': 'saga'}\n",
      "best score: 0.9749\n",
      "\n",
      "Dataset is scaled\n",
      "\n",
      "Model: Decision Tree with Gini\n",
      "\n",
      "k value: 3\n",
      "test_accuracy(gini): 0.9219512195121952\n",
      "training_accuracy(gini): 0.9560669456066946\n",
      "\n",
      "best param: {'max_depth': 4, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2}\n",
      "best score: 0.9582\n",
      "\n",
      "k value: 5\n",
      "test_accuracy(gini): 0.9560975609756097\n",
      "training_accuracy(gini): 0.9539748953974896\n",
      "\n",
      "best param: {'max_depth': 6, 'max_features': None, 'min_samples_leaf': 2, 'min_samples_split': 6}\n",
      "best score: 0.9582\n",
      "\n",
      "k value: 7\n",
      "test_accuracy(gini): 0.9512195121951219\n",
      "training_accuracy(gini): 0.9539748953974896\n",
      "\n",
      "best param: {'max_depth': 7, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 6}\n",
      "best score: 0.9582\n",
      "\n",
      "Model: Decision Tree with Entropy\n",
      "\n",
      "k value: 3\n",
      "test_accuracy(entropy): 0.9512195121951219\n",
      "training_accuracy(entropy): 0.9832635983263598\n",
      "\n",
      "best param: {'max_depth': 7, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
      "best score: 0.9582\n",
      "\n",
      "k value: 5\n",
      "test_accuracy(entropy): 0.9512195121951219\n",
      "training_accuracy(entropy): 0.9728033472803347\n",
      "\n",
      "best param: {'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "best score: 0.9519\n",
      "\n",
      "k value: 7\n",
      "test_accuracy(entropy): 0.9414634146341463\n",
      "training_accuracy(entropy): 0.9790794979079498\n",
      "\n",
      "best param: {'max_depth': 4, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 10}\n",
      "best score: 0.975\n",
      "\n",
      "Model: SVM\n",
      "\n",
      "k value: 3\n",
      "best param: {'C': 0.1, 'gamma': 10, 'kernel': 'linear'}\n",
      "best score: 0.977\n",
      "\n",
      "k value: 5\n",
      "best param: {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "best score: 0.975\n",
      "\n",
      "k value: 7\n",
      "best param: {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "best score: 0.9686\n",
      "\n",
      "Model: Logistic Regression\n",
      "\n",
      "k value: 3\n",
      "best param: {'C': 0.01, 'max_iter': 1000, 'solver': 'liblinear'}\n",
      "best score: 0.9686\n",
      "\n",
      "k value: 5\n",
      "best param: {'C': 0.1, 'max_iter': 1000, 'solver': 'liblinear'}\n",
      "best score: 0.9749\n",
      "\n",
      "k value: 7\n",
      "best param: {'C': 0.1, 'max_iter': 1000, 'solver': 'liblinear'}\n",
      "best score: 0.9706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#model parameter: \n",
    "# 1: Decision Tree with Gini\n",
    "# 2: Decision Tree with Entropy\n",
    "# 3: SVM\n",
    "# 4: Logistic Regression\n",
    "\n",
    "model_list=['Decision Tree with Gini','Decision Tree with Entropy','SVM','Logistic Regression']\n",
    "for s in (0,1):\n",
    "    if s==1:\n",
    "        print('Dataset is scaled\\n')\n",
    "    for model in (1,2,3,4):\n",
    "        print('Model: {}\\n'.format(model_list[model-1]))\n",
    "        for k in (3,5,7):\n",
    "            print('k value:',k)\n",
    "            run_model(df, k, model,s)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
